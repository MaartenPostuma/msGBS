# Authors v1.0 (Legacy):    ..., ..., ... & ...
# Authors v2.0 (New):       Jelle van der Heide
# Date:                     ../../..
# 
# This is the main msGBS pipeline file. Here, the environment-variables are defined and a connection is 
# made between the rule all and the additional rule-files.
# --------------------------------------------------------------------------------------------------------------------

import pandas as pd
import os

configfile: "../Config/config.yaml"
# -- define run conditions from config.
if config["mapper_mode"]=="All":
    MAPPER=["Bowtie", "Bwa", "Star"]
else:
    MAPPER=config["mapper_mode"]


# -- define dataframe from barcodefile.
df = pd.read_csv(os.path.join(config["input_dir"],config["barcode_file"]), sep='\t')
df['run'] = df['rawR1'].str.replace("_R1.fq.gz","",regex=False)
df['sample']=df["Sample"]
# -- define variables from the barcode dataframe.

DUPES=df['Sample'].duplicated().any()

# -- define wildcards from the barcode dataframe.
MONOS = df['Sample'][df['Sample'].str.contains("mono")]
NONMONOS=df['Sample'][~df['Sample'].str.contains("mono")]

RUN = df.rawR1.str.replace("_R1.fq.gz","",regex=False).unique()
readfile  = [1, 2]
grouped = df.groupby("run")["sample"].apply(set)
LANESAMPLE = grouped.to_dict()
DEMULTIPLEXSAMPLES = {}
for lane, samples in LANESAMPLE.items():
    for sample in samples:
        DEMULTIPLEXSAMPLES[sample] = lane



if config["ref_mode"]=="Available":
    monoFile=pd.read_csv(config['mono_select_loc'], sep='\t')
    MONOS=monoFile['Monos']
    SAMPLES = pd.concat([MONOS,NONMONOS])
    include: "Rules/Preprocessing.smk"
    include: "Rules/AdjustRef.smk"
else:
    SAMPLES = pd.concat([MONOS,NONMONOS])
    include: "Rules/Reference_creation.smk"
    include: "Rules/Blasting.smk"
    include: "Rules/Preprocessing.smk"
    include: "Rules/Mapping.smk"
    include: "Rules/Analysis.smk"


# -- define which rule-files to implement.





# -- define rule all, or essentially the output goal of this pipeline.
rule all:
    input:
        #allpreprocessed=expand("{allpreprocessed_dir}/preprocessed_R{readfile}.fq.gz",  allpreprocessed_dir=config["allpreprocessed_dir"], readfile=readfile),
        #bamOut=expand("{output_dir}/Mapping/Bamout/{mapper}/mapping_rg_{sample}.bam",output_dir=config["output_dir"], mapper=MAPPER, sample=SAMPLES),
        statscsv=expand("{output_dir}/Analysis/{mapper}/stats.tsv",output_dir=config["output_dir"], mapper=MAPPER),
        Data1=expand("{output_dir}/Analysis/{mapper}/Data_1_Clusters_Target_vs_Reason_to_remove_8_15_1000_summed_per_species.txt", output_dir=config["output_dir"], mapper=MAPPER),
        Data2=expand("{output_dir}/Analysis/{mapper}/Data_2_Clusters_filtered_due_to_homology_to_8_15_1000.txt", output_dir=config["output_dir"], mapper=MAPPER),
        Data3=expand("{output_dir}/Analysis/{mapper}/Data_3_READ_COUNT_removed_CLUSTERS_SUM_8_15_1000.tsv", output_dir=config["output_dir"], mapper=MAPPER),
        Data4=expand("{output_dir}/Analysis/{mapper}/Data_4_SUM_8_15_1000.tsv", output_dir=config["output_dir"], mapper=MAPPER),
        Data5=expand("{output_dir}/Analysis/{mapper}/Data_5_SUM_MINREAD_FILTER_8_15_1000.tsv", output_dir=config["output_dir"], mapper=MAPPER),
        alllogs=expand("{output_dir}/logSummary/multiQClogsummary.html", output_dir=config["output_dir"]),
        allBlastResults=expand("{output_dir}/Blasting/blastresults.tsv", output_dir=config["output_dir"]),
        demultiReads_R1=expand("{output_dir}/Preprocessing/samples/{nonmonos}.1.fq.gz",output_dir=config["output_dir"],nonmonos=NONMONOS),
        demultiReads_R2=expand("{output_dir}/Preprocessing/samples/{nonmonos}.2.fq.gz",output_dir=config["output_dir"],nonmonos=NONMONOS),
        monoReads_R1=expand("{output_dir}/Preprocessing/samples/{monos}.1.fq.gz",output_dir=config["output_dir"],monos=MONOS),
        monoReads_R2=expand("{output_dir}/Preprocessing/samples/{monos}.2.fq.gz",output_dir=config["output_dir"],monos=MONOS),
